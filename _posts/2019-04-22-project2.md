---
layout: post
title: Predicting Phone Prices with Regression
---



### PREMISE

For this project, I was given the leeway to choose a topic that I wanted to explore with linear regression techniques. I ended up choosing to predict phone prices based on the different specifications of the phone.


-----

### DATA


I used data from [GSM Arena](https://www.gsmarena.com/) to scrape and analyze. The parameters that I chose to keep for my final regression model were:

* Length (mm)
* Width (mm)
* Thickness (mm)
* Weight (g)
* Rear Camera Quality (megapixels)
* Screen Size (inches)
* Battery Capacity (mAh)
* Memory Capacity (MB)
* RAM (MB)

Many of the columns of my dataframe that was scraped had numbers embedded in text. For example, the cell for the dimensions would read "191.7 x 101 x 9.4 mm (7.55 x 3.98 x 0.37 in) and "Non-removable Li-Ion 3400 mAh battery (12.92 Wh)" for the battery, so most of the data cleaning was spent extracting the numbers for further use. The next challenge was to convert all GB and MB measurements to MB for consistency using a function and applying it to each column. Afterwards, it was time for testing the assumptions of Linear Regression, and then Modeling!


-----

### Step 1: Testing Assumptions

Unfortunately, my data did not end up meeting all the necessary assumptions for using Linear Regression. The dependent variable was not normally distributed, so a log transformation was used to normalize it. Also, some of the covariates were not independent of each other.



### Step 2: Modeling
I wanted to make a more interpretive model, with coefficients that made sense for what I was trying to predict. At first, running a naive Ordinary Linear Regression gave me an R<sup>2</sup> of 0.47.

However, after trying both Ridge and Lasso regularization to my model, Ridge gave my the highest R<sup>2</sup> value while decreasing the impact that my collinear parameters had on my price prediction. Length, width, and screen size were highly collinear based on the pairplot and correlation map investigated in Python. Both Ridge and Lasso helped minimize their impact on the model by giving them smaller coefficients.



-----


### RESULTS



My regression model using Ridge regularization turned out to have an R<sup>2</sup> value of 0.47, with an R<sup>2</sup> of 0.41 when using it to predict on my holdout data. Although my naive OLS model had the same score, I chose Ridge as my champion model due to its ability to decrease the importance of collinear parameters. The most impactful parameter on phone price by far was the camera quality, with a standardized coefficient of 0.219, followed by Thickness(0.118), Memory(0.113), and Weight(0.104). I expected the internal hardware specifications to be more impactful, such as the RAM, memory, and battery. It was a surprise that the camera quality had such an influence on phone prices. The dimensions of the phone turned out to be relatively unimportant features to the model.

Although my model had a low R<sup>2</sup> score, I believe that the results wwere still useful in determining what factors of a phone would contribute to a higher price on the market.


-----

